{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a00769e5-a04a-4ad3-bc06-fbd666119cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para el conjunto de datos Wine del ejercicio anterior, realiza un modelo de ensamble de árboles de decisión donde se agrupen 500 modelos predictores\n",
    "# entrenados con 75 observaciones de la muestra de entrenamiento cada uno. Para poder validar el modelo, divide el conjunto de datos en 128 \n",
    "# observaciones para la muestra de entrenamiento y 50 para la muestra de validación.\n",
    "# a) Con reemplazamiento (bagging)\n",
    "# b) Sin reemplazamiento (pasting)\n",
    "# c) Realizando Random Forest (fijando el número máximo de nodos hoja en 4)\n",
    "# ¿Con qué método se obtiene la mejor predicción?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6674a13b-bf36-40f2-99f5-e5e80d55bad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178 entries, 0 to 177\n",
      "Data columns (total 13 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   alcohol                       178 non-null    float64\n",
      " 1   malic_acid                    178 non-null    float64\n",
      " 2   ash                           178 non-null    float64\n",
      " 3   alcalinity_of_ash             178 non-null    float64\n",
      " 4   magnesium                     178 non-null    float64\n",
      " 5   total_phenols                 178 non-null    float64\n",
      " 6   flavanoids                    178 non-null    float64\n",
      " 7   nonflavanoid_phenols          178 non-null    float64\n",
      " 8   proanthocyanins               178 non-null    float64\n",
      " 9   color_intensity               178 non-null    float64\n",
      " 10  hue                           178 non-null    float64\n",
      " 11  od280/od315_of_diluted_wines  178 non-null    float64\n",
      " 12  proline                       178 non-null    float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 18.2 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Cada modelo predictor del ensamble debe emplear 75 de las 128 observadiones de entrenamiento\n",
    "\n",
    "# Se comienza cargando el dataset\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine # Para importar el conjunto de datos\n",
    "\n",
    "wine = load_wine(as_frame=True) # Se importa el conjunto de datos como un dataframe (as_frame=True)\n",
    "\n",
    "# Variables predictoras\n",
    "print(wine.data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c1a5c834-11c1-4cdb-9758-51af39f6776a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad teórica de datos en el conjunto de entrenamiento: 128.0\n",
      "Cantidad de datos en el conjunto de entrenamiento creado: 128\n",
      "Cantidad teórica de datos en el conjunto de validación: 50.0\n",
      "Cantidad de datos en el dataset de test creado: 50\n"
     ]
    }
   ],
   "source": [
    "# Se divide el dataset en un conjunto de entrenamiento y un conjunto de test. El conjunto de entrenamiento está formado por 128 datos de los 178\n",
    "# totales. El tanto por uno para el conjunto de test es (178-128)/178.\n",
    "import numpy as np\n",
    "# Función para crear el conjunto de entrenamiento y el conjunto de validación\n",
    "# 'dataset' es el dataframe y 'porcentaje_validacion' es la proporción en tanto por un 1 para el conjunto de validación.\n",
    "def particiones(target, dataset, porcentaje_validacion):\n",
    "    \n",
    "    # 'int' se queda con la parte entera. Con len(dataset) se calcula la longitud de cada columna\n",
    "    tamaño_validacion = int(round(len(dataset)*porcentaje_validacion,0))\n",
    "\n",
    "    # Crea un array con los índices de 'dataset' dispuestos de forma aleatoria\n",
    "    mezclar_indices = np.random.permutation(len(dataset))\n",
    "\n",
    "    # Se queda con tantos índices del array anterior como datos debe haber en el conjunto de validación\n",
    "    indices_validacion = mezclar_indices[:tamaño_validacion]\n",
    "\n",
    "    # Los índices restantes son para los datos del dataset de entrenamiento\n",
    "    indices_entrenamiento = mezclar_indices[tamaño_validacion:]\n",
    "\n",
    "    # Se devuelven los dataset de entrenamiento y de test. 'iloc' saca filas\n",
    "    return dataset.iloc[indices_entrenamiento], dataset.iloc[indices_validacion], target.iloc[indices_entrenamiento], target.iloc[indices_validacion]\n",
    "\n",
    "# Se llama a la función para crear el conjunto de entrenamiento (train) y el conjunto de validación (test). \n",
    "X_train, X_test, y_train, y_test = particiones(wine.target, wine.data, (178-128)/178)\n",
    "\n",
    "# Se comprueba que la partición es correcta calculando la cantidad de datos en cada conjunto\n",
    "print('Cantidad teórica de datos en el conjunto de entrenamiento:', round(len(wine.data)*128/178,0))\n",
    "print('Cantidad de datos en el conjunto de entrenamiento creado:', len(train))\n",
    "print('Cantidad teórica de datos en el conjunto de validación:', round(len(wine.data)*(178-128)/178,0))\n",
    "print('Cantidad de datos en el dataset de test creado:', len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "860427ec-cf2c-45fe-af76-18b28f726619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n"
     ]
    }
   ],
   "source": [
    "# Apartado a)\n",
    "# Se utiliza el método de ensamble tipo bagging con el modelo árbol de decisión\n",
    "from sklearn.ensemble import BaggingClassifier # Para realizar ensamble tipo bagging\n",
    "from sklearn.tree import DecisionTreeClassifier # Para crea árbol de decisión\n",
    "from sklearn.metrics import accuracy_score # Para medir bondad del ajuste\n",
    "\n",
    "# Se crea objeto BaggingClassifier\n",
    "# Con bootstrap = True se establece que el método de ensamble es tipo bagging\n",
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(random_state=3), n_estimators=500, max_samples=75, bootstrap=True, random_state=3)\n",
    "\n",
    "# Se ajusta el modelo\n",
    "bag_clf.fit(X_train, y_train)\n",
    "\n",
    "# Estimaciones del modelo sobre el conjunto de validación\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "\n",
    "# Bondad del ajuste\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e66c6b0-4f77-4a93-b2d9-72170c1aecb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se obtiene un valor de accuracy muy alto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f016d638-a3a3-4d64-9f9f-2a75e3c7aaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n"
     ]
    }
   ],
   "source": [
    "# Apartado b)\n",
    "# Se repite el apartado anterior, pero con bootstrap=False como argumento en la creación del objeto BaggingClassifier para que el método de ensamble\n",
    "# sea de tipo pasting.\n",
    "\n",
    "# Se crea objeto BaggingClassifier\n",
    "# Con bootstrap = False se establece que el método de ensamble es tipo pasting\n",
    "pas_clf = BaggingClassifier(DecisionTreeClassifier(random_state=3), n_estimators=500, max_samples=75, bootstrap=False, random_state=3)\n",
    "\n",
    "# Se ajusta el modelo\n",
    "pas_clf.fit(X_train, y_train)\n",
    "\n",
    "# Estimaciones del modelo sobre el conjunto de validación\n",
    "y_pred_pas = pas_clf.predict(X_test)\n",
    "\n",
    "# Bondad del ajuste\n",
    "print(accuracy_score(y_test, y_pred_pas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "65bbf196-0dab-4596-991b-e903c7dba198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La medida del accuracy es la misma tanto con el método de bagging como con el de pasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "19d3a802-f1a1-495b-ba02-19df474d9a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n"
     ]
    }
   ],
   "source": [
    "# Apartado c)\n",
    "from sklearn.ensemble import RandomForestClassifier # Para crear Random Forest\n",
    "\n",
    "# Se crea objeto Random Forest\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=4, random_state=3, max_samples=75)\n",
    "\n",
    "# Se ajusta el modelo\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "# Estimaciones del modelo sobre el conjunto de validación\n",
    "y_pred_rf = rnd_clf.predict(X_test)\n",
    "\n",
    "# Bondad del ajuste\n",
    "print(accuracy_score(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5626d9d2-ecd4-420f-81b5-a932b5c2cbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    }
   ],
   "source": [
    "# Se obtiene el mismo valor para accuracy que en los dos apartados anteriores, por lo que no se puede diferenciar un método de ensamble como el mejor.\n",
    "# Comparamos los resultados obtenidos con los métodos de ensamble con aquellos que se obtendrían con un modelo simple de árbol de decisión.\n",
    "tree_clf = DecisionTreeClassifier(random_state=3, max_depth=3)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "y_pred_tree = tree_clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d501d3cc-69f3-48da-a208-f33fd0afa7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se obtiene un menor valor para accuracy con el modelo de árbol de decisión, lo cual pone de manifiesto que es un peor modelo que los anteriores."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
